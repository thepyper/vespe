**Implementation Plan: Vespe - Basic Agent Development**

**Goal:** Develop a basic Rust agent capable of interacting with a Large Language Model (LLM) via a Command-Line Interface (CLI). This will serve as the foundational component for the "Vespe" multi-agent system.

**Phase 1: Core Setup and Basic Agent Functionality**

**Step 1: Project Initialization and Basic Dependencies**

*   **Action:** Create `Cargo.toml`, `src/main.rs`, `src/lib.rs`.
*   **`Cargo.toml` Content:**
    *   Add essential dependencies: `tokio` (full features), `serde` (derive), `serde_json`, `toml`, `clap` (full features), `anyhow`, `thiserror`, `tracing`, `tracing-subscriber`, `reqwest` (json, rustls-tls), `async-trait`.
*   **`src/main.rs` Content:**
    *   Initialize `tracing_subscriber` for basic logging.
    *   Define an `async fn main()` that calls an `async fn run()` from `lib.rs`.
*   **`src/lib.rs` Content:**
    *   Define a placeholder `pub async fn run() -> anyhow::Result<()>`.
*   **Git Action:** Commit changes: "feat: Initial project setup and basic dependencies."

**Step 2: Configuration Loading**

*   **Action:** Implement configuration loading for global and agent-specific settings.
*   **`src/config/models.rs` Content:**
    *   Define `LlmConfig` struct (provider, model_id, api_key, etc.).
    *   Define `AgentDefinition` struct (name, llm_config).
    *   Define `GlobalConfig` struct (default_llm_config).
*   **`src/config/mod.rs` Content:**
    *   Implement `load_global_config()`: Loads default global config (e.g., from `~/.config/vespe/config.toml` or hardcoded defaults).
    *   Implement `load_project_config()`: Loads project-specific config from `.vespe/config.toml` and applies overrides to the global config.
*   **Git Action:** Commit changes: "feat: Implement configuration loading for global and agent settings."

**Step 3: LLM Client Implementation**

*   **Action:** Create an abstract LLM client and a concrete implementation for a chosen provider.
*   **`src/llm/models.rs` Content:**
    *   Define `ChatMessage` struct (role, content).
    *   Define `LlmResponse` struct (content).
*   **`src/llm/providers/openai.rs` (or `ollama.rs`) Content:**
    *   Implement a client for a specific LLM provider (e.g., OpenAI).
    *   Function to send a list of `ChatMessage` and receive `LlmResponse`.
    *   Handle API key, endpoint, and request/response serialization.
*   **`src/llm/llm_client.rs` Content:**
    *   Define `LlmClient` trait with `async fn generate_response(&self, messages: Vec<ChatMessage>) -> anyhow::Result<LlmResponse>`.
    *   Implement `GenericLlmClient` struct that holds `LlmConfig` and dispatches calls to the appropriate provider client.
*   **Git Action:** Commit changes: "feat: Implement LLM client with OpenAI provider."

**Step 4: Basic Agent Definition and Instantiation**

*   **Action:** Define the `Agent` trait and implement a `BasicAgent`.
*   **`src/agent/agent_trait.rs` Content:**
    *   Define `Agent` trait: `name() -> &str`, `async fn execute(&self, input: &str) -> anyhow::Result<String>`.
*   **`src/agent/models.rs` Content:**
    *   Refine `AgentDefinition` to include `name` and `llm_config`.
*   **`src/agent/impls/basic_agent.rs` Content:**
    *   Implement `BasicAgent` struct, holding `AgentDefinition` and `GenericLlmClient`.
    *   Implement `Agent` trait for `BasicAgent`. The `execute` method will construct a prompt from the input and send it to the `GenericLlmClient`.
*   **`src/agent/agent_manager.rs` Content:**
    *   Implement `AgentManager` struct.
    *   `load_agent_definition(name: &str) -> anyhow::Result<AgentDefinition>`: Loads agent definition from `.vespe/agents/{name}.json` (or `.toml`).
    *   `create_agent(definition: AgentDefinition) -> anyhow::Result<Box<dyn Agent>>`: Instantiates `BasicAgent` from definition.
*   **Git Action:** Commit changes: "feat: Implement basic agent definition, trait, and instantiation."

**Step 5: CLI Integration and Agent Interaction**

*   **Action:** Integrate CLI parsing to allow interaction with the basic agent.
*   **`src/cli/commands.rs` Content:**
    *   Use `clap` to define a subcommand `chat` with arguments `<AGENT_NAME>` and `<MESSAGE>`.
*   **`src/main.rs` Content:**
    *   Parse CLI arguments using `clap`.
    *   If `chat` command:
        *   Load configuration.
        *   Use `AgentManager` to load `AgentDefinition` and create the agent.
        *   Call `agent.execute(message)`.
        *   Print the agent's response.
*   **Git Action:** Commit changes: "feat: Integrate CLI for basic agent chat interaction."
