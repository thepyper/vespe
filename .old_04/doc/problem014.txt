c:\Proj\xxx\025_006.Vespe\vespe\buzz\training>python train.py
Loading dataset...

Dataset loaded and split:
DatasetDict({
    train: Dataset({
        features: ['full_text', 'spans'],
        num_rows: 182
    })
    test: Dataset({
        features: ['full_text', 'spans'],
        num_rows: 21
    })
})

Tokenizing and aligning labels with new span-based method...

Setting up model and trainer...
Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
C:\Users\thepy\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
c:\Proj\xxx\025_006.Vespe\vespe\buzz\training\train.py:159: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(

Starting training...
{'eval_loss': 1.4631010293960571, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.5414808206958073, 'eval_runtime': 0.4293, 'eval_samples_per_second': 48.922, 'eval_steps_per_second': 4.659, 'epoch': 1.0}
{'eval_loss': 1.155092477798462, 'eval_precision': 0.088, 'eval_recall': 0.2619047619047619, 'eval_f1': 0.13173652694610777, 'eval_accuracy': 0.7332738626226584, 'eval_runtime': 0.426, 'eval_samples_per_second': 49.299, 'eval_steps_per_second': 4.695, 'epoch': 2.0}
{'eval_loss': 1.028627872467041, 'eval_precision': 0.07894736842105263, 'eval_recall': 0.21428571428571427, 'eval_f1': 0.11538461538461539, 'eval_accuracy': 0.7511150758251561, 'eval_runtime': 0.4334, 'eval_samples_per_second': 48.453, 'eval_steps_per_second': 4.615, 'epoch': 3.0}
{'train_runtime': 49.9572, 'train_samples_per_second': 10.929, 'train_steps_per_second': 0.721, 'train_loss': 1.4732872645060222, 'epoch': 3.0}