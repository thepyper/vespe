//! This module defines the data structures used to represent content exchanged with
//! external models (LLMs). It provides a structured way to build prompts, distinguishing
//! between system instructions, user input, and agent responses. The core components
//! are `ModelContentItem`, representing a single part of a conversation, and
//! `ModelContent`, which aggregates multiple `ModelContentItem`s into a complete prompt.

use serde::{Deserialize, Serialize};

/// Represents content originating from the system.
///
/// This struct encapsulates text that provides instructions or context from the
/// system to the model. It's typically used for setting up the model's behavior
/// or providing high-level guidance.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SystemModelContent {
    text: String,
}

/// Represents content originating from the user's prompt or context files.
///
/// This struct holds text input provided directly by the user or gathered from
/// user-defined context files. It forms the primary input for the model's responses.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserModelContent {
    text: String,
}

/// Represents content generated by an agent or a previous model turn.
///
/// This struct stores text that has been generated by an AI agent or a prior
/// interaction with an external model. It allows for multi-turn conversations
/// and contextual responses.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentModelContent {
    author: String,
    text: String,
}

/// An enum that represents a single piece of content in a conversation or prompt
/// sent to a model. It distinguishes between system instructions, user input,
/// and agent responses.
///
/// Each variant wraps a specific content type ([`SystemModelContent`], [`UserModelContent`], [`AgentModelContent`]),
/// allowing the execution engine to categorize and format different parts of a prompt
/// appropriately for an external model.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ModelContentItem {
    /// Content provided by the system, typically for instructions or context.
    System(SystemModelContent),
    /// Content provided by the user, representing direct input or queries.
    User(UserModelContent),
    /// Content generated by an AI agent or a previous model response.
    Agent(AgentModelContent),
    /// Content to merge to next message as a prefix
    MergeDownstream(String),
    /// Content to merge to previous message as a postfix
    MergeUpstream(String),
}

impl ModelContentItem {
    /// Creates a new `ModelContentItem::User` from a string slice.
    ///
    /// # Arguments
    ///
    /// * `text` - The text content for the user message.
    ///
    /// # Returns
    ///
    /// A `ModelContentItem` variant containing the user's text.
    ///
    /// # Examples
    pub fn user(text: &str) -> Self {
        ModelContentItem::User(UserModelContent { text: text.into() })
    }

    /// Creates a new `ModelContentItem::System` from a string slice.
    ///
    /// # Arguments
    ///
    /// * `text` - The text content for the system message.
    ///
    /// # Returns
    ///
    /// A `ModelContentItem` variant containing the system's text.
    ///
    /// # Examples
    pub fn system(text: &str) -> Self {
        ModelContentItem::System(SystemModelContent { text: text.into() })
    }

    /// Creates a new `ModelContentItem::Agent` from a string slice.
    ///
    /// # Arguments
    ///
    /// * `text` - The text content for the agent's message.
    ///
    /// # Returns
    ///
    /// A `ModelContentItem` variant containing the agent's text.
    ///
    /// # Examples
    pub fn agent(author: &str, text: &str) -> Self {
        ModelContentItem::Agent(AgentModelContent {
            author: author.into(),
            text: text.into(),
        })
    }

    pub fn merge_downstream(text: &str) -> Self {
        ModelContentItem::MergeDownstream(text.into())
    }

    pub fn merge_upstream(text: &str) -> Self {
        ModelContentItem::MergeUpstream(text.into())
    }

    pub fn is_empty(&self) -> bool {
        self.to_string().trim().is_empty()
    }
}

impl ToString for ModelContentItem {
    /// Converts the `ModelContentItem` into its raw text content.
    ///
    /// This implementation of `ToString` simply returns the underlying text
    /// of the content item, without any additional formatting or headers.
    ///
    /// # Returns
    ///
    /// A `String` containing the raw text content.
    ///
    /// # Examples
    fn to_string(&self) -> String {
        match self {
            ModelContentItem::System(content) => format!("{}", content.text),
            ModelContentItem::User(content) => format!("{}", content.text),
            ModelContentItem::Agent(content) => format!("{}", content.text),
            ModelContentItem::MergeDownstream(content) => content.clone(),
            ModelContentItem::MergeUpstream(content) => content.clone(),
        }
    }
}

#[derive(Clone, Copy)]
pub enum PromptFormat {
    Parts,
}

/// A struct representing a full conversation or a multi-part prompt.
///
/// `ModelContent` is a collection of `ModelContentItem`s, ordered to form a complete
/// prompt that can be sent to an external model. It allows for building complex
/// conversational contexts.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelContent(pub Vec<ModelContentItem>);

impl ModelContent {
    /// Creates a new, empty `ModelContent` instance.
    ///
    /// # Returns
    ///
    /// A new `ModelContent` with an empty list of items.
    ///
    /// # Examples
    pub fn new() -> Self {
        ModelContent(Vec::new())
    }

    pub fn from_item(item: ModelContentItem) -> Self {
        ModelContent(vec![item])
    }

    /// Extends the current `ModelContent` with items from another `ModelContent` instance.
    ///
    /// The items from the `content` parameter are appended to the end of the
    /// current `ModelContent`'s list of items.
    ///
    /// # Arguments
    ///
    /// * `content` - Another `ModelContent` instance whose items will be appended.
    ///
    /// # Examples
    pub fn extend(&mut self, content: ModelContent) {
        self.0.extend(content.0.into_iter());
    }

    /// Appends a single `ModelContentItem` to the end of the `ModelContent`.
    ///
    /// # Arguments
    ///
    /// * `item` - The `ModelContentItem` to be added.
    ///
    /// # Examples
    pub fn push(&mut self, item: ModelContentItem) {
        self.0.push(item);
    }

    fn embed_in_prompt_as_part(item: &ModelContentItem) -> String {
        match item {
            ModelContentItem::System(content) => {
                let text = content.text.trim();
                if !text.is_empty() {
                    format!("---\nSystem:\n{}\n", text)
                } else {
                    text.into()
                }
            }
            ModelContentItem::User(content) => {
                let text = content.text.trim();
                if !text.is_empty() {
                    format!("---\nUser:\n{}\n", text)
                } else {
                    text.into()
                }
            }
            ModelContentItem::Agent(content) => {
                let text = content.text.trim();
                if !text.is_empty() {
                    format!("Assistant:\n{}\n", text)
                } else {
                    text.into()
                }
            }
            _ => {
                panic!("cannot be embedded, bug!");
            }
        }
    }

    fn embed_in_prompt(item: &ModelContentItem, format: PromptFormat) -> String {
        match format {
            PromptFormat::Parts => Self::embed_in_prompt_as_part(item),
        }
    }

    /// Converts the entire `ModelContent` into a single formatted prompt string.
    ///
    /// This method iterates through all `ModelContentItem`s and formats each one
    /// using `ModelContentItem::to_prompt()`, then joins them with newline characters.
    /// The result is a complete prompt ready for an external model.
    ///
    /// # Returns
    ///
    /// A `String` representing the concatenated and formatted prompt.
    ///
    /// # Examples    
    pub fn to_prompt(&self, format: PromptFormat) -> String {
        // Pre pass: delete empty messages
        let non_empty_items = &self
            .0
            .iter()
            .filter(|x| !x.is_empty())
            .collect::<Vec<&ModelContentItem>>();

        // First pass: merge downstream and upstream messages
        let mut merged_items: Vec<ModelContentItem> = Vec::new();
        let mut downstream_merges: Vec<String> = Vec::new();

        for item in non_empty_items {
            match item {
                ModelContentItem::System(_) | ModelContentItem::User(_) => {
                    let mut current_text = item.to_string();

                    if !downstream_merges.is_empty() {
                        let prefix = downstream_merges.join("\n");
                        current_text = format!("{}\n{}", prefix, current_text);
                        downstream_merges.clear();
                    }

                    let new_item = match item {
                        ModelContentItem::System(_) => ModelContentItem::system(&current_text),
                        ModelContentItem::User(_) => ModelContentItem::user(&current_text),
                        _ => unreachable!(), // We are in the match arm for these types
                    };
                    merged_items.push(new_item);
                }
                ModelContentItem::Agent(agent_item) => {
                    let mut current_text = item.to_string();

                    if !downstream_merges.is_empty() {
                        let prefix = downstream_merges.join("\n");
                        current_text = format!("{}\n{}", prefix, current_text);
                        downstream_merges.clear();
                    }

                    let new_item = ModelContentItem::agent(&agent_item.author, &current_text);

                    merged_items.push(new_item);
                }
                ModelContentItem::MergeDownstream(s) => {
                    downstream_merges.push(s.clone());
                }
                ModelContentItem::MergeUpstream(s) => {
                    if let Some(last_item) = merged_items.last_mut() {
                        let text_to_append = s.clone();
                        match last_item {
                            ModelContentItem::System(c) => {
                                c.text = format!("{}\n{}", c.text, text_to_append)
                            }
                            ModelContentItem::User(c) => {
                                c.text = format!("{}\n{}", c.text, text_to_append)
                            }
                            ModelContentItem::Agent(c) => {
                                c.text = format!("{}\n{}", c.text, text_to_append)
                            }
                            _ => {} // Should not happen as we only push normal items
                        }
                    }
                    // If there's no previous item, we ignore the upstream merge.
                }
            }
        }

        // Second pass: merge consecutive messages of the same type
        let mut final_merged_items: Vec<ModelContentItem> = Vec::new();
        let mut iter = merged_items.into_iter();

        if let Some(mut last) = iter.next() {
            for item in iter {
                match (&mut last, &item) {
                    (
                        ModelContentItem::System(last_content),
                        ModelContentItem::System(item_content),
                    ) => {
                        last_content.text.push('\n');
                        last_content.text.push_str(&item_content.text);
                    }
                    (
                        ModelContentItem::User(last_content),
                        ModelContentItem::User(item_content),
                    ) => {
                        last_content.text.push('\n');
                        last_content.text.push_str(&item_content.text);
                    }
                    (
                        ModelContentItem::Agent(last_content),
                        ModelContentItem::Agent(item_content),
                    ) => {
                        last_content.text.push('\n');
                        last_content.text.push_str(&item_content.text);
                    }
                    _ => {
                        final_merged_items.push(last);
                        last = item;
                    }
                }
            }
            final_merged_items.push(last);
        }

        let prompt = final_merged_items
            .iter()
            .map(|item| Self::embed_in_prompt(item, format))
            .collect::<Vec<String>>()
            .join("\n");

        /*
        Aggiungere questo con gemini e' peggiorativo per multi-persona (example 01), vedendo
        di nuovo "Assistant" prende di nuovo la personalita' del pagliaccio e non del corvo.
        prompt.push_str("Assistant:\n"); // TODO rendere dipendente dal tipo di formattazione?
        */

        prompt
    }
}

impl Default for ModelContent {
    /// Returns a default, empty `ModelContent` instance.
    ///
    /// This is equivalent to calling `ModelContent::new()`.
    ///
    /// # Examples
    fn default() -> Self {
        Self::new()
    }
}

impl ToString for ModelContent {
    /// Converts the entire `ModelContent` into a single raw text string.
    ///
    /// This method concatenates the raw text content of all `ModelContentItem`s,
    /// without any additional formatting or message type headers.
    ///
    /// # Returns
    ///
    /// A `String` containing the concatenated raw text content.
    ///
    /// # Examples
    fn to_string(&self) -> String {
        self.0
            .iter()
            .map(|item| item.to_string())
            .collect::<Vec<String>>()
            .join("\n")
    }
}
