{
  "status": "Completed",
  "reply": "Here's a draft for the `README.md` file:\n\n```markdown\n# Vespe: Your Collaborative Mind-Mapping Tool with LLMs\n\nVespe, through its `ctx` command-line interface, empowers users and Large Language Models (LLMs) to collaboratively build and share \"mind maps.\" It achieves this by working with an interconnected set of text documents, referred to as \"contexts.\" These contexts are essentially Markdown files augmented with special commands that facilitate dynamic interaction with LLMs.\n\n## Getting Started: A Quick Demo\n\nLet's dive into a simple example to see `ctx` in action. Imagine you have a context file like this (e.g., `.ctx/contexts/test/test4.md`):\n\n```markdown\n@include rules\n\nTell me 3 violet things.\n\n<!-- answer-be05e54f-cfe6-4ca6-be4f-6bb700000000:begin {}  -->\n<!-- answer-be05e54f-cfe6-4ca6-be4f-6bb700000000:end {}  -->\n\nTell me something nice.\n\n<!-- answer-8014ce3a-23b4-4e17-afe0-287db0000000:begin { system: agent/gemini_25_flash_yolo }  -->\n<!-- answer-8014ce3a-23b4-4e17-afe0-287db0000000:end {}  -->\n```\n\nInitially, the `<!-- answer-... -->` blocks would contain `@answer` tags. When you execute this context using `ctx`, the LLM processes the prompts, and the `ctx` tool injects the responses directly into your Markdown file, transforming the tags into \"anchors\" (HTML comments with UUIDs). The example above, after execution, might look like this:\n\n```markdown\n@include rules\n\nTell me 3 violet things.\n\n<!-- answer-be05e54f-cfe6-4ca6-be4f-6bb700000000:begin {}  -->\n1. Amethyst\n2. Lavender\n3. Violets (the flower)\n<!-- answer-be05e54f-cfe6-4ca6-be4f-6bb700000000:end {}  -->\n\nTell me something nice.\n\n<!-- answer-8014ce3a-23b4-4e17-afe0-287db0000000:begin { system: agent/gemini_25_flash_yolo }  -->\nYou are doing great! Keep up the excellent work.\n<!-- answer-8014ce3a-23b4-4e17-afe0-287db0000000:end {}  -->\n```\n\nThis seamless integration allows for iterative development of ideas, where the LLM's contributions become an integral part of your living document.\n\n## Key Commands (Tags)\n\nVespe extends standard Markdown with a set of powerful commands, or \"tags,\" prefixed with `@`. These tags enable various functionalities, from including other contexts to interacting with LLMs and managing variables.\n\n### `@include <path/to/context>`\n\nThe `@include` tag allows you to embed content from another context file directly into the current one. This is crucial for modularity and reusability, enabling you to build complex mind maps from smaller, focused contexts.\n\n**Example:**\n`@include common_definitions`\n\n### `@answer { [parameters] }`\n\nThe `@answer` tag is the core of LLM interaction. It instructs `ctx` to send the surrounding text (or a specified input) to an LLM and then insert the LLM's response back into the document.\n\n**Parameters:**\n*   `system`: (Optional) Specifies a system prompt or agent to guide the LLM's behavior.\n*   `input`: (Optional) Specifies an alternative input source for the LLM, instead of the surrounding text.\n*   `output`: (Optional) Redirects the LLM's output to a specified file.\n\n**Example:**\n\n```markdown\nWhat are the main benefits of cloud computing?\n\n<!-- answer-uuid-goes-here:begin {}  -->\n<!-- answer-uuid-goes-here:end {}  -->\n```\n\nAfter execution, the LLM's answer will appear between the `begin` and `end` markers.\n\n### `@set <variable_name> = <value>`\n\nThe `@set` tag allows you to define and manage variables within your contexts. These variables can be used to control the behavior of other tags or to store information relevant to your mind map.\n\n**Example:**\n`@set project_name = \"Vespe\"`\n\n### Other Tags (Coming Soon / Advanced)\n\nVespe is designed to be extensible, with plans for additional tags like `@decide`, `@choose`, and `@derive` to enable even more sophisticated LLM-driven workflows.\n\n## Project Structure\n\n*   **`.ctx/`**: This directory holds all Vespe-specific configuration and state.\n    *   **`contexts/`**: Your collection of Markdown context files.\n    *   **`.meta/`**: Stores execution state for dynamic tags (e.g., LLM responses).\n*   **`src/ast2/`**: Handles parsing of context files into an Abstract Syntax Tree (AST).\n*   **`src/execute2/`**: The core execution engine that interprets the AST, interacts with LLMs, and updates context files.\n*   **`src/bin/ctx/main.rs`**: The main CLI application.\n\n## Installation and Usage\n\n(Instructions for installation and basic usage commands like `ctx init`, `ctx context new`, `ctx context execute`, `ctx watch` would go here.)\n```\nI've tried to incorporate all your points:\n1.  **Purpose:** \"permettere ad utente e llm di condividere una mappa mentale\" is translated to \"empowers users and Large Language Models (LLMs) to collaboratively build and share 'mind maps.'\"\n2.  **Mechanism:** Explained that it works on \"contexts\" which are \"Markdown files augmented with special commands that facilitate dynamic interaction with LLMs.\"\n3.  **Examples:** Used the `test4.md` example, showing the before and after of an `@answer` tag being processed into an anchor with LLM output. I've used placeholder UUIDs for brevity.\n4.  **Tag Description:** Provided descriptions for `@include`, `@answer`, and `@set`, including parameters for `@answer`. I also added a section for \"Other Tags\" to hint at future extensibility.\n\nI've also added a brief \"Project Structure\" section for context and a placeholder for \"Installation and Usage\" which you can fill in later.\n\nPlease review this draft and let me know if you'd like any changes or additions.\n```\n"
}