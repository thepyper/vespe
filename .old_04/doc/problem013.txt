c:\Proj\xxx\025_006.Vespe\vespe\buzz\training>python train.py
Loading dataset...

Dataset loaded and split:
DatasetDict({
    train: Dataset({
        features: ['full_text', 'spans'],
        num_rows: 182
    })
    test: Dataset({
        features: ['full_text', 'spans'],
        num_rows: 21
    })
})

Tokenizing and aligning labels with new span-based method...
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 182/182 [00:00<00:00, 3910.31 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 2791.59 examples/s]

Setting up model and trainer...
Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
C:\Users\thepy\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\transformers\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
c:\Proj\xxx\025_006.Vespe\vespe\buzz\training\train.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(

Starting training...
{'eval_loss': 1.4939757585525513, 'eval_precision': 0.00911854103343465, 'eval_recall': 0.07142857142857142, 'eval_f1': 0.016172506738544475, 'eval_accuracy': 0.5771632471008028, 'eval_runtime': 0.5024, 'eval_samples_per_second': 41.801, 'eval_steps_per_second': 3.981, 'epoch': 1.0}
{'eval_loss': 1.1582868099212646, 'eval_precision': 0.10559006211180125, 'eval_recall': 0.40476190476190477, 'eval_f1': 0.16748768472906406, 'eval_accuracy': 0.7270294380017841, 'eval_runtime': 0.4758, 'eval_samples_per_second': 44.139, 'eval_steps_per_second': 4.204, 'epoch': 2.0}
{'eval_loss': 1.0346959829330444, 'eval_precision': 0.0763888888888889, 'eval_recall': 0.2619047619047619, 'eval_f1': 0.11827956989247314, 'eval_accuracy': 0.7404103479036575, 'eval_runtime': 0.4328, 'eval_samples_per_second': 48.525, 'eval_steps_per_second': 4.621, 'epoch': 3.0}
{'train_runtime': 50.8376, 'train_samples_per_second': 10.74, 'train_steps_per_second': 0.708, 'train_loss': 1.5140868292914496, 'epoch': 3.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:50<00:00,  1.41s/it]

Training complete. Saving the best model...
Model saved to buzz-parser-v2/final_model

To export to ONNX, run the following command:
python export_to_onnx.py --model_path buzz-parser-v2/final_model
