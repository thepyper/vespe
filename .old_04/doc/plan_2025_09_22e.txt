Piano di modifica per il formato di segmentazione del modello Marker

Obiettivo: Cambiare il formato di segmentazione da un markup linea per linea (`<CATEGORY> riga`) a un markup con tag di inizio e fine (`<CATEGORY>contenuto</CATEGORY>`), eliminando la necessità del tag `<NL>`.

Flusso attuale:
1.  Il `data_generator` utilizza `labeling_prompt.hbs` per istruire un LLM a generare una stringa di testo grezza (`marker_response`). Questa stringa utilizza il formato:
    ```
    <CATEGORY_A> contenuto della riga 1
    <CATEGORY_B> contenuto della riga 2
    <NL>
    <CATEGORY_C> contenuto della riga 3
    ```
2.  Questa `marker_response` viene passata alla funzione `save_labeled_example` in `src/bin/data_generator/pipeline.rs`.
3.  `save_labeled_example` chiama `segmentation_to_json_conversion` (sempre in `src/bin/data_generator/pipeline.rs`) per parsare questo testo grezzo in un oggetto JSON strutturato (con campi `full_text` e `spans`).
4.  Il JSON risultante viene salvato in un file.
5.  `buzz/training/prepare_dataset.py` consuma questi file JSON.

Nuovo formato desiderato:
```
<CATEGORY_A>
contenuto della riga 1
contenuto della riga 2
</CATEGORY_A>
<CATEGORY_B>
contenuto della riga 3
</CATEGORY_B>
```
(Nota: Nessun tag `<NL>`, e il contenuto può estendersi su più righe all'interno di un blocco di categoria.)

Fase 1: Modifica del prompt di generazione dei dati (`src/bin/data_generator_templates/labeling_prompt.hbs`)

1.  Aggiornare la sezione "TOKEN MARKING RULES":
    *   Rimuovere le istruzioni relative alla divisione per nuova riga e all'uso di `<NL>`.
    *   Introdurre regole per l'uso di tag accoppiati `<CATEGORY>` e `</CATEGORY>` per racchiudere interi segmenti, consentendo ai segmenti di contenere nuove righe.
2.  Aggiornare la sezione "OUTPUT FORMAT":
    *   Riscrivere completamente questa sezione per descrivere il nuovo formato con tag accoppiati.
    *   Sottolineare che l'output dovrebbe essere una sequenza di blocchi `<CATEGORY>contenuto</CATEGORY>`.
    *   Dichiarare esplicitamente che non devono essere utilizzati tag `<NL>` o altri markup intermedi.
3.  Aggiornare le sezioni "Example Output" e "EXAMPLES":
    *   Riscrivere tutti gli esempi per riflettere il nuovo formato con tag accoppiati. Ad esempio, un esempio come:
        ```
        <TEXT>I'll search for information:
        <TOOL_CALL>{"name": "web_search", "query": "python"}
        <NL>
        <TEXT>This should help!
        ```
        diventerebbe:
        ```
        <TEXT>I'll search for information:</TEXT>
        <TOOL_CALL>{"name": "web_search", "query": "python"}</TOOL_CALL>
        <TEXT>This should help!</TEXT>
        ```
        (Nota: L'esempio sopra assume che il contenuto JSON stesso non contenga nuove righe che devono essere preservate *all'interno* del blocco `TOOL_CALL`. Se lo facesse, il blocco `TOOL_CALL` si estenderebbe su più righe.)

Fase 2: Modifica del parsing della segmentazione (`src/bin/data_generator/pipeline.rs`)

1.  Aggiornamento della funzione `segmentation_to_json_conversion`:
    *   Rimozione del parsing linea per linea: L'attuale ciclo `for (line_no, line) in input.lines().enumerate()` e la sua logica per la gestione di `<NL>` e `<CATEGORY> riga` dovranno essere sostituiti.
    *   Implementazione del parsing a blocchi:
        *   Utilizzare espressioni regolari o manipolazione di stringhe per trovare le occorrenze di `<([A-Z_]+)>(.*?)</\1>` (o pattern simile) per estrarre il nome della categoria e il suo contenuto.
        *   Per ogni blocco estratto, identificare il `CATEGORY_NAME` e il `content` tra i tag.
        *   Il `content` dovrebbe includere tutti i caratteri, comprese le nuove righe, tra i tag di apertura e chiusura.
        *   Aggiornare di conseguenza i vettori `full_text` e `spans`, calcolando le posizioni `start` e `end` in base alla stringa `full_text`.
    *   Gestione degli errori: Adattare i messaggi di errore per riflettere il nuovo formato atteso (ad esempio, "Tag di chiusura mancante per <CATEGORY_NAME>", "Tag malformato").
    *   Mantenimento della struttura JSON: Assicurarsi che la struttura JSON di output (`full_text` e `spans` con `start`, `end`, `category`) rimanga identica all'output attuale, in modo che `buzz/training/prepare_dataset.py` non richieda modifiche.

Fase 3: Verifica

1.  Compilazione del progetto Rust: Eseguire `cargo build` nella directory root di `vespe` per assicurarsi che tutte le modifiche compilino senza errori.
2.  Generazione di nuovi dati: Eseguire il binario `data_generator` per creare nuovi file JSON di esempio. Questo testerà la Fase 1 (LLM che genera il nuovo formato) e la parte iniziale della Fase 2 (salvataggio dell'output).
3.  Ispezione del JSON generato: Ispezionare manualmente alcuni file JSON generati per confermare che:
    *   Il campo `full_text` concatena correttamente tutto il contenuto.
    *   L'array `spans` identifica correttamente `start`, `end` e `category` per ogni blocco, in base al nuovo formato.
4.  Esecuzione della preparazione del dataset: Eseguire `python buzz/training/prepare_dataset.py` (o il comando pertinente) utilizzando i file JSON appena generati per assicurarsi che lo script Python possa ancora elaborare i dati senza problemi.

Sei d'accordo con questo piano?