# Design Document: Gestione di Sequenze Lunghe con Sliding Window

Data: 2025-09-19

## 1. Il Problema: Limite di 512 Token

Il modello che abbiamo addestrato (`distilbert-base-uncased`) ha un limite architetturale fisso: può processare al massimo 512 token alla volta. Questo limite deriva dal suo pre-training e non può essere cambiato. Come abbiamo visto, se proviamo a dargli in pasto una sequenza più lunga, il programma va in crash.

La domanda è: come possiamo usare il nostro modello per analizzare testi che superano questo limite?

## 2. La Soluzione: Sliding Window (Finestre Mobili)

L'idea proposta dall'utente è la soluzione standard e corretta a questo problema. Si tratta di "far scorrere" una finestra di analisi lungo tutto il testo.

### Concetti Chiave

1.  **Window Size (Dimensione della Finestra):** La dimensione massima che il modello può accettare. Nel nostro caso, **512** token.
2.  **Stride (Passo):** Il numero di token di cui la finestra avanza ad ogni passo. Questo valore deve essere *inferiore* alla dimensione della finestra per creare una sovrapposizione.
3.  **Overlap (Sovrapposizione):** L'area di testo che viene analizzata più di una volta, da finestre consecutive. L'ampiezza della sovrapposizione è `Window Size - Stride`. Una buona sovrapposizione è cruciale per la robustezza del risultato.

**Esempio Pratico (la tua proposta):**
-   **Window Size:** 512 token.
-   **Overlap:** 256 token.
-   **Stride:** `512 - 256 = 256` token.

Questo significa che:
-   Il modello analizza i token da 0 a 511.
-   Poi si sposta in avanti di 256 token e analizza il blocco da 256 a 767.
-   Poi analizza il blocco da 512 a 1023, e così via.

I token nella parte centrale (da 256 a 511 nella prima finestra) vengono analizzati due volte, una volta alla fine della prima finestra e una volta all'inizio della seconda. Questo ci dà più "opinioni" del modello su come classificarli.

### La Sfida: Unire i Risultati (Stitching)

Eseguire il modello su ogni finestra è facile. La parte difficile è decidere l'etichetta finale per i token che si trovano nelle aree di sovrapposizione e che quindi ricevono più di una predizione.

-   **Approccio Naive (sconsigliato):** Prendi solo la predizione della prima o dell'ultima finestra che ha visto il token. È semplice ma ignora informazioni preziose.

-   **Approccio Robusto (Raccomandato): Votazione basata sui Logits**
    Il modello non restituisce solo un'etichetta, ma un vettore di "punteggi" (logits) per ogni etichetta possibile, per ogni token. L'etichetta finale è semplicemente quella con il punteggio più alto (`argmax`).
    La strategia migliore è:
    1.  Per ogni finestra, esegui l'inferenza e **salva l'intero vettore di logits** per ogni token in quella finestra.
    2.  Dopo aver processato tutte le finestre, ti ritroverai con più vettori di logits per i token nelle aree di sovrapposizione.
    3.  Per ogni token, **somma (o fai la media) dei vettori di logits** che ha ricevuto da tutte le finestre che lo contenevano.
    4.  Infine, calcola l'`argmax` sul vettore di logits mediato/sommato per ottenere l'etichetta finale e più probabile per quel token.

Questo approccio è il più robusto perché aggrega l'"opinione" del modello da contesti diversi (il token visto alla fine di una finestra vs. all'inizio di un'altra), portando a una classificazione finale più stabile e accurata.

## 3. Implementazione Pratica

Questa logica andrebbe implementata nella funzione `run_inference` del nostro script di test (e successivamente nel crate Rust).

La libreria `transformers` può aiutare a generare automaticamente le finestre sovrapposte, semplificando parte del lavoro. Il cuore dell'implementazione diventa quindi l'aggregazione dei logits e la ricostruzione della sequenza finale di etichette.
