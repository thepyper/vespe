{
  "name": "my_agent",
  "llm_config": {
    "provider": "ollama",
    "model_id": "llama3", 
    "temperature": 0.7,
    "max_tokens": 512
  }
}