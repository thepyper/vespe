# Design Document: LLM Output Segmentation (Project Buzz)

Data: 2025-09-19

## 1. Obiettivo

Il progetto "buzz" mira a creare un sistema robusto per segmentare l'output testuale grezzo di un Large Language Model (LLM) in categorie funzionali definite per un agent software. Le categorie iniziali sono:

-   `Text`: Testo libero destinato all'utente finale.
-   `Thought`: Ragionamenti interni del modello, non da mostrare.
-   `ToolCall`: Una richiesta strutturata per eseguire un tool specifico.
-   `ToolResponse`: Il risultato dell'esecuzione di un tool, da reinserire nel contesto del modello.

Il problema nasce dal fatto che gli LLM, anche se istruiti, spesso non riescono a rispettare rigorosamente formati di output come JSON o XML, producendo un testo semi-strutturato che richiede un parsing più intelligente.

## 2. Analisi dell'Idea Proposta: Sliding Window a Livello di Carattere

L'idea di usare una "sliding window" per classificare ogni carattere è concettualmente un approccio di **Sequence Labeling**.

-   **Come funzionerebbe:** Un modello (tipicamente una rete neurale ricorrente come LSTM/GRU o un Transformer) analizza una sequenza di caratteri (la "finestra") e assegna a ogni carattere un'etichetta (es. `B-THOUGHT`, `I-THOUGHT`, `B-TOOLCALL`, `I-TOOLCALL`, `O` per "Outside").
-   **Pro:**
    -   **Massima Granularità:** In teoria, può catturare i confini tra i blocchi con precisione a livello di singolo carattere, anche in formati molto confusionari.
    -   **Flessibilità:** Non dipende da marcatori espliciti (come tag XML) e può imparare pattern impliciti.
-   **Contro:**
    -   **Complessità Elevata:** Sviluppare, allenare e fare il deploy di un modello del genere da zero è un progetto di Machine Learning significativo.
    -   **Fame di Dati:** I modelli a livello di carattere richiedono una grande quantità di dati etichettati per generalizzare bene. La creazione di questo training set sarebbe un'impresa notevole.
    -   **Costo Computazionale:** L'inferenza può essere più lenta rispetto ad approcci più semplici, specialmente su testi lunghi.
    -   **Alternative Esistenti:** È un approccio potente, ma potrebbe essere come usare un cannone per uccidere una mosca, specialmente all'inizio.

**Conclusione:** L'idea è valida e rappresenta lo stato dell'arte per problemi di "Named Entity Recognition" e "Sequence Labeling", ma è probabilmente prematura come punto di partenza. Il costo di implementazione e di creazione dei dati è molto alto.

## 3. Alternative Pratiche e Percorso Raccomandato

Suggerisco un approccio incrementale, partendo dalla soluzione più semplice ed efficace per poi aggiungere complessità solo se necessario.

### Livello 1: Parser Basato su Regole e State Machine (Il Punto di Partenza Pragmatico)

Questo approccio si basa sull'assunto che il modello *tenta* di seguire le istruzioni, ma lo fa in modo imperfetto.

-   **Concetto:** Si definiscono dei marcatori (es. `Thought:`, `<tool_call>`, `Tool Call:`) che indicano l'inizio di un blocco. Un parser scorre il testo e, quando incontra un marcatore, cambia stato (es. da `parsing_text` a `parsing_thought`) e accumula contenuto fino al marcatore successivo.
-   **Architettura:** Una **State Machine**. Gli stati possono essere `OutOfBlock`, `InText`, `InThought`, `InToolCall`. Le transizioni sono attivate da match di espressioni regolari.
-   **Vantaggi:**
    -   **Semplice e Veloce:** Facile da implementare e molto rapido in esecuzione.
    -   **Nessun Training:** Non richiede dati né addestramento.
    -   **Efficace all'80%:** Risolve la maggior parte dei casi in cui il modello è "quasi" corretto.
    -   **Ideale per Rust:** Si implementa elegantemente in Rust.

### Livello 2: Parser Combinators

Questa è una versione più elegante e robusta del Livello 1.

-   **Concetto:** Invece di scrivere manualmente la state machine e le regex, si usano delle funzioni di ordine superiore (combinators) per definire la grammatica del testo che ci aspettiamo.
-   **Libreria Consigliata (Rust):** `nom`. È una libreria fantastica, creata esattamente per questo tipo di problemi. Permette di scrivere parser dichiarativi, componibili e molto performanti. Potresti definire un "parser di blocco" che riconosce `tag_apertura ~ contenuto ~ tag_chiusura` in modo molto espressivo.
-   **Vantaggi:**
    -   **Robusto e Componibile:** Meno soggetto a errori di logica rispetto a una state machine manuale.
    -   **Performance Eccellenti:** `nom` è estremamente ottimizzato.
    -   **Codice Dichiarativo:** Il codice del parser assomiglia a una descrizione della sua grammatica, rendendolo più leggibile.

### Livello 3: Classificatore di Blocchi (Approccio ML Semplificato)

Se i parser basati su regole falliscono, il passo successivo è usare il ML, ma in modo più semplice rispetto all'idea iniziale.

-   **Concetto:**
    1.  Pre-processare il testo dividendolo in blocchi (es. per linea o per paragrafo).
    2.  Usare un modello di classificazione testuale per etichettare ogni blocco (`text`, `thought`, etc.).
-   **Implementazione:**
    -   Si può usare un modello pre-allenato (es. un piccolo BERT/DistilBERT) specializzato per la classificazione.
    -   **In Rust:** La sfida è l'ecosistema. Si potrebbe usare `candle` o `tract` per eseguire un modello esportato in formato ONNX. È fattibile ma richiede competenze di ML Ops.
-   **Vantaggi:** Molto più robusto delle regole, può capire l'intento semantico di un blocco anche senza marcatori espliciti.
-   **Svantaggi:** Richiede un training set (anche se più piccolo di quello per il sequence labeler) e una pipeline di ML.

## 4. Best Practices e Suggerimenti

-   **Inizia Semplice:** Parti dal **Livello 2 (Parser Combinators con `nom`)**. È il miglior compromesso tra semplicità, robustezza e performance in Rust. Ti darà una base solida e ti costringerà a definire bene la "grammatica" che ti aspetti.
-   **Raccogli Dati Fin da Subito:** Ogni volta che il tuo parser fallisce, salva l'output grezzo del modello. Questo sarà il tuo tesoro: un dataset di "casi difficili" che potrai usare in futuro per allenare un modello di ML (Livello 3) se il parser a regole non dovesse più bastare.
-   **Architettura del Crate `buzz`:**
    -   `lib.rs`: Definisci le strutture dati principali (es. `struct SegmentedOutput { segments: Vec<Segment> }`, `enum Segment { Text(String), Thought(String), ... }`).
    -   `parser.rs`: Implementa il tuo parser usando `nom`.
    -   `error.rs`: Definisci i tuoi tipi di errore per un buon error handling.

## 5. Strumenti Consigliati (Rust)

1.  **`nom`**: La scelta principale per il parsing. È potente, performante e idiomatico in Rust.
2.  **`regex`**: Utile in combinazione con `nom` per riconoscere i marcatori.
3.  **`serde`**: Per serializzare l'output strutturato del parser in JSON o altri formati.
4.  **`thiserror`** e **`anyhow`**: Per una gestione degli errori pulita e robusta.

---

**In sintesi: ti consiglio caldamente di non iniziare con un approccio di deep learning custom. Parti con un parser basato su `nom`, che è lo strumento perfetto per questo lavoro in Rust. È un'ottima sfida di programmazione, produce codice manutenibile e ti darà risultati eccellenti per una vasta gamma di output semi-strutturati.**
