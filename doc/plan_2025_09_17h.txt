# Plan: Refactoring LLM Markdown Policy Abstraction

## Objective
To abstract the LLM markdown policy into a flexible and extensible `Trait`, allowing for easy switching and testing of different markdown formats for LLM interaction.

## Motivation
*   The current markdown policy is hardcoded, limiting flexibility and making it difficult to adapt to new LLM requirements or experiment with different interaction styles.
*   There is a need to easily experiment with different markdown policies to find the most effective one for guiding the LLM and parsing its responses.
*   Improve maintainability and testability of LLM interaction logic by centralizing policy definition.
*   Decouple the internal message representation from LLM-specific formatting concerns.

## Key Concepts
*   **`MarkdownPolicy` Trait:** A Rust trait that defines the interface for handling markdown policies, including methods for generating system prompts, parsing LLM responses, and formatting queries.
*   **`Message` Enum:** A neutral, internal representation of messages exchanged with the LLM. This enum will encapsulate different types of messages (system, user, assistant, tool output).
*   **`AssistantContent` Enum:** An enum specifically for representing the various types of content that an assistant (LLM) might generate within a single message (e.g., plain text, internal thoughts, tool calls).
*   **`ToolCall` Struct:** A data structure to represent a call to an external tool, including the tool's name and its arguments.
*   **`ToolOutput` Struct:** A data structure to represent the output received from an external tool after it has been executed.

## Phased Approach

### Phase 1: Define Core Data Structures (`Message`, `AssistantContent`, `ToolCall`, `ToolOutput`)

1.  **Create `src/llm/messages.rs`:**
    *   This new file will be dedicated to housing the core data structures that represent messages and their content.
2.  **Define `Message` Enum:**
    *   `pub enum Message {`
    *   `    System(String),`
    *   `    User(String),`
    *   `    Assistant(Vec<AssistantContent>),`
    *   `    Tool(ToolOutput),`
    *   `}`
    *   This enum will serve as the universal internal representation of communication turns.
3.  **Define `AssistantContent` Enum:**
    *   `pub enum AssistantContent {`
    *   `    Text(String),`
    *   `    Thought(String),`
    *   `    ToolCall(ToolCall),`
    *   `}`
    *   This enum allows an assistant's response to be composed of multiple distinct parts.
4.  **Define `ToolCall` Struct:**
    *   `pub struct ToolCall {`
    *   `    pub name: String,`
    *   `    pub arguments: String, // Expected to be a JSON string`
    *   `}`
    *   This struct captures the essential information for invoking a tool.
5.  **Define `ToolOutput` Struct:**
    *   `pub struct ToolOutput {`
    *   `    pub tool_name: String,`
    *   `    pub output: String,`
    *   `}`
    *   This struct stores the result of a tool's execution.
6.  **Add necessary `use` statements and `pub` visibility** to ensure these structures are accessible throughout the `llm` module and potentially beyond.
7.  **Update `src/llm/mod.rs`:** Add `pub mod messages;` to export the contents of the new `messages.rs` file.

### Phase 2: Define `MarkdownPolicy` Trait

1.  **Create `src/llm/markdown_policy.rs`:**
    *   This new file will contain the definition of the `MarkdownPolicy` trait.
2.  **Define `MarkdownPolicy` Trait:**
    ```rust
    use super::messages::{Message, AssistantContent, ToolCall, ToolOutput}; // Adjust path as needed

    pub trait MarkdownPolicy {
        /// Returns the markdown prompt string to be included in the system prompt.
        /// This prompt instructs the LLM on the expected markdown format for its responses.
        fn markdown_prompt(&self) -> String;

        /// Parses the raw LLM response string into a vector of internal `Message` enums.
        /// This method is responsible for interpreting the LLM's markdown output.
        /// Returns an error if parsing fails or the response does not conform to the policy.
        fn parse_response(&self, response: &str) -> Result<Vec<Message>, Box<dyn std::error::Error>>;

        /// Formats a vector of internal `Message` enums into a string suitable for the LLM query.
        /// This method converts the internal representation into the markdown format expected by the LLM.
        fn format_query(&self, messages: &[Message]) -> String;
    }
    ```
3.  **Add necessary `use` statements** within `markdown_policy.rs` to bring `Message`, `AssistantContent`, `ToolCall`, and `ToolOutput` into scope.
4.  **Update `src/llm/mod.rs`:** Add `pub mod markdown_policy;` to export the new trait.

### Phase 3: Implement a Basic `DefaultMarkdownPolicy`

1.  **Create `src/llm/impls/default_markdown_policy.rs`:**
    *   This file will contain the concrete implementation of the `MarkdownPolicy` trait for the current, default markdown format.
2.  **Implement `MarkdownPolicy` for `DefaultMarkdownPolicy` struct:**
    *   **`markdown_prompt()`:** This method will return the exact markdown instructions currently being used in the system prompt. It should clearly define how `ToolCall`s (e.g., using specific code blocks or markers), `Thought`s (e.g., using specific markdown for internal reasoning), and `Text` segments should be formatted by the LLM.
    *   **`parse_response()`:** This will be the most intricate part. It needs to parse the LLM's raw response string and extract `ToolCall`s, `Thought`s, and `Text` segments based on the defined markdown rules. This might involve:
        *   Using regular expressions to identify patterns for tool calls and thoughts.
        *   A simple state machine to process the response line by line or segment by segment.
        *   Robust error handling for malformed responses.
    *   **`format_query()`:** This method will convert a `Vec<Message>` (containing `System`, `User`, `Assistant`, `Tool` messages) back into a single string format that the LLM understands, strictly adhering to the defined markdown policy. This will involve serializing `ToolCall` objects into their markdown representation and formatting `Thought` messages appropriately.
3.  **Update `src/llm/impls/mod.rs`:** Add `pub mod default_markdown_policy;` to export the new implementation.

### Phase 4: Integrate `MarkdownPolicy` into `LlmClient`

1.  **Modify `src/llm/llm_client.rs`:**
    *   **Update `LlmClient` struct:** The `LlmClient` struct should be modified to hold an instance of `Box<dyn MarkdownPolicy>`. This allows for dynamic dispatch and easy swapping of policies at runtime.
        ```rust
        use super::markdown_policy::MarkdownPolicy; // Adjust path
        // ... other uses
        pub struct LlmClient {
            // ... existing fields
            markdown_policy: Box<dyn MarkdownPolicy>,
        }
        ```
    *   **Update `new` constructor:** The `new` constructor for `LlmClient` should now accept an instance of `Box<dyn MarkdownPolicy>`.
        ```rust
        pub fn new(/* ... existing params, */ markdown_policy: Box<dyn MarkdownPolicy>) -> Self {
            // ...
            LlmClient {
                // ...
                markdown_policy,
            }
        }
        ```
    *   **Refactor LLM interaction methods:** Update methods that interact with the LLM (e.g., `send_message`, `generate_response`, or similar) to utilize the `markdown_policy` for:
        *   **Getting the system prompt:** Call `self.markdown_policy.markdown_prompt()` to retrieve the policy instructions for the system prompt.
        *   **Formatting the query:** Call `self.markdown_policy.format_query(&messages)` to convert the internal `Vec<Message>` into the LLM-specific query string.
        *   **Parsing the LLM's raw response:** Call `self.markdown_policy.parse_response(&raw_llm_response_string)` to convert the LLM's raw text output into a structured `Vec<Message>`.

### Phase 5: Update Call Sites and Testing

1.  **Identify all call sites of `LlmClient`:** Search the codebase for where `LlmClient::new()` is called. These locations will need to be updated.
2.  **Refactor `LlmClient` instantiation:** At each call site, create an instance of `DefaultMarkdownPolicy` and box it before passing it to the `LlmClient` constructor:
    ```rust
    use crate::llm::impls::default_markdown_policy::DefaultMarkdownPolicy; // Adjust path
    // ...
    let default_policy = Box::new(DefaultMarkdownPolicy::new()); // Assuming DefaultMarkdownPolicy has a new() method
    let llm_client = LlmClient::new(/* ... existing params, */ default_policy);
    ```
3.  **Refactor existing LLM interaction logic:** Replace any direct string manipulation or custom parsing logic related to markdown formatting and response interpretation with calls to the `markdown_policy` methods on the `LlmClient` instance.
4.  **Create Comprehensive Unit Tests:**
    *   **For `src/llm/messages.rs`:** If any custom serialization/deserialization is added, test it thoroughly.
    *   **For `src/llm/impls/default_markdown_policy.rs`:**
        *   Test `markdown_prompt` to ensure it returns the expected instructional string.
        *   Test `parse_response` with a wide range of valid and invalid LLM response strings. This should include responses containing `ToolCall`s, `Thought`s, plain `Text`, and various combinations, as well as malformed responses to ensure robust error handling.
        *   Test `format_query` with diverse `Vec<Message>` inputs to verify correct markdown output for the LLM.
    *   **For `src/llm/llm_client.rs`:** Ensure that the `LlmClient` correctly utilizes the injected `MarkdownPolicy` for all LLM interactions.
5.  **Run Integration Tests:** Execute all existing integration tests to ensure that the refactoring has not introduced any regressions or broken existing functionality.

### Phase 6: Cleanup and Documentation

1.  **Remove old hardcoded markdown logic:** Systematically identify and remove all remnants of the previous hardcoded markdown formatting and parsing logic from `LlmClient` and any other affected modules.
2.  **Update comments and documentation:**
    *   Add clear comments to the `MarkdownPolicy` trait, `Message` enums, and `ToolCall`/`ToolOutput` structs.
    *   Update the `LlmClient` documentation to reflect its dependency on `MarkdownPolicy`.
    *   Provide guidance on how to implement new `MarkdownPolicy` instances.
3.  **Review code for idiomatic Rust:** Ensure the newly written and refactored code adheres to Rust best practices, style guides, and idiomatic patterns.

## Rollback Plan
*   In the event that any phase introduces critical errors that cannot be quickly resolved, the project will be reverted to the previous stable commit using Git. Regular commits after each successful sub-phase are highly recommended.

## Success Criteria
*   The application compiles and runs without any errors.
*   All existing functionality related to LLM interaction works precisely as it did before the refactoring.
*   New `MarkdownPolicy` implementations can be easily added and swapped into the `LlmClient` without modifying core LLM interaction logic.
*   All newly created unit tests and existing integration tests pass successfully, demonstrating the correctness and robustness of the refactored code.
*   The codebase is cleaner, more modular, and easier to maintain and extend.
