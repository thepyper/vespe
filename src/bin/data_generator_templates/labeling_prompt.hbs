TRAINING DATA LABELING - TOKEN MARKING SEGMENTATION

Analyze a language model's response and mark each meaningful unit with its category to create training data for text segmentation.
Response should (but could not) contain a tool call of the tool specified in the next section.

=== INPUT DATA ===
Available tools:
{{{tools_specs}}}

=== CLASSIFICATION CATEGORIES ===

**TEXT:** User-facing content
- Direct answers, explanations, confirmations
- Results presentation, summaries
- Polite conversational elements

**THOUGHT:** Internal reasoning about the task
- "I need to...", "Let me...", "The user wants..."
- Analysis of the situation or approach
- Planning statements

**TOOL_CALL:** Tool invocation content
- JSON structures for any tool calling
- Tool parameters and arguments
- Technical tool-calling syntax (even if malformed)

=== TOKEN MARKING RULES ===

**Segmentation Guidelines:**
- You MUST split on newline, even if it is internal to structured data such as JSON or any other;
- You CAN split anywhere else if you need to begin a new segment.
      
=== OUTPUT FORMAT ===

Each segment falls into one of the following 2 cases:

1. It is result of a newline split, then output format is:
<CATEGORY>segment
<NL>
Notice that the newline tag is NOT on the same line of the category and segment.

2. It is result of a non-newline split, then output format is:
<CATEGORY>segment

The wanted result is segmented output is a perfect reconstruction of the original output.

You CANNOT output anything else than the segment conversion into one of there two cases.
You CANNOT output any explanation of how you decided segmentation.
You CANNOT output any markup other than specified in the two cases.

Example Input: 
I'll search for information: {\"name\": \"web_search\", \"query\": \"python\"} 
This should help!

Example Output:
<TEXT>I'll search for information: 
<TOOL_CALL>{\"name\": \"web_search\", \"query\": \"python\"} 
<NL>
<TEXT>This should help!

=== TOOL-SPECIFIC RECOGNITION ===
For any tool, mark as TOOL_CALL:
- Any JSON structure containing tool name
- Parameter structures matching the tool specifications
- Malformed attempts at using any tool
- References to any tool functionality

=== EXAMPLES ===

Example 1:
Input: 
I understand your request. 
Let me read the specified file:
{\"name\": \"read_file\", \"path\": \"data.txt\"}
The contents are displayed above.

Output:
<TEXT>I understand your request. 
<NL>
<THOUGHT>Let me read the specified file:
<NL>
<TOOL_CALL>{\"name\": \"read_file\", \"path\": \"data.txt\"}
<NL>
<TEXT>The contents are displayed above.
<NL>

Example 2:
Input: 
Hmm, I need to think about this. I'll use echo: {\"text\": \"hello world\"} 
Done!

Output:
<THOUGHT>Hmm, I need to think about this. 
<TEXT>I'll use echo: 
<TOOL_CALL>{\"text\": \"hello world\"} 
<NL>
<TEXT>Done!
<NL>

=== PROCESSING INSTRUCTIONS ===

1. Read the full model response
2. Identify segmentation boundaries
3. Classify each segment based on context and content
4. Mark each unit with appropriate category
5. Ensure complete coverage (every word/unit gets a label)
6. Double-check that TOOL_CALL segments relate to {{{tool_name}}}

=== ORIGINL QUERY TO THE MODEL ===
{{{small_query}}}

=== MODEL RESPONSE TO SEGMENT ===
{{{small_reply}}}
